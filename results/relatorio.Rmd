---
title: "Análise Estatística de Fatores de Risco para Doença Coronária"
author: "Wenderson Santos"
output: 
    html_document:
        theme: flatly
        toc: true
        code_folding: show
    pdf_document:
        toc: true
        highlight: tango
        latex_engine: xelatex
---


```{r setup, include=FALSE}
source(here::here("R", "imports.R"))
source(here::here("R", "getData.R"))
source(here::here("R", "getDataBin.R"))
source(here::here("R", "modelPrep.R"))
source(here::here("R", "functions.R"))

```


# Introdução
O dataset provém de um estudo que analisou 297 pacientes na Cleveland Clinic para avaliação da Doença Coronária;

O experimento envolveu 3 estágios:
 
* Teste de esforço (protocolo de Bruce) 
* Cinefluoroscopia
* Angiografia coronária
* Cintilografia com Tálio-201

## Variáveis analisadas

* age
* sex
* cp : tipo de dor no peito
    * Angina Típica: Atende a três critérios (localização atrás do osso do peito, provocada por esforço/estresse e aliviada por repouso).

    * Angina Atípica: Atende a apenas dois desses critérios.

    * Dor Não Anginosa: Atende a apenas um ou nenhum dos critérios, sugerindo que a causa pode ser muscular ou gástrica (não cardíaca).

    * Assintomático: O paciente não sente dor, mas o médico ainda assim solicitou os exames devido a outros fatores de risco (como idade ou histórico familiar).

* thalach : Frequência cardíaca máxima atingida antes da exaustão ou sintomas (no teste de esforço).
* exang : Indica se o paciente sentiu angina (dor) durante o exercício.
* oldpeak : diferença entre a posição do segmento ST (ECG) no repouso e no pico do esforço (thalac) (quanto maior essa diferença, maior é a área do coração que sofre por falta de sangue)
* slope : Enquanto o oldpeak diz o quanto a linha afundou, o slope diz como ela se comporta logo após o afundamento. Existem três tipos principais de inclinação:

    * Value 0: Upsloping (Ascendente): A linha afunda, mas sobe rápido. É comum em exercícios intensos e nem sempre indica doença grave.

    * Value 1: Flat (Plano): A linha afunda e fica "reta". É um sinal clássico e preocupante de isquemia.

    * Value 2: Downsloping (Descendente): A linha afunda e continua descendo. É o sinal mais grave de todos, indicando que o coração está em alto sofrimento isquêmico. (mesmo após a interrupção do esforço)


* ca : Número de vasos principais com depósitos de cálcio ou interrupções no fluxo.
    * 0: Nenhuma calcificação significativa (indício de artérias limpas)

    * 1, 2 o
    u 3: Indica que a doença está presente em um, dois ou três vasos principais.
* thal : Avalia se o sangue está chegando a todas as partes do coração durante o repouso e após o esforço.

    * 0 = Normal: O contraste se distribui uniformemente por todo o coração.

    * 1 = Fixed Defect (Defeito Fixo): Uma parte do coração não recebe o contraste nem no esforço, nem no repouso. Isso geralmente indica tecido morto (cicatriz de um infarto antigo).

    * 2 = Reversable Defect (Defeito Reversível): O coração parece normal em repouso, mas "falta sangue" em alguma região durante o esforço. Isso é o sinal clássico de isquemia ativa: a artéria está entupida, mas o tecido ainda está vivo e sofrendo.
* condition (target)

* trestbps : É a pressão arterial medida no momento da internação.
* fbs : Glicemia de Jejum é maior ou menor que 120mg/dl (binário)
* chol : nível total de colesterol no sangue.
* restecg : 

    * Value 0 (Normal): O coração em repouso não apresenta irregularidades elétricas.

    * Value 1 (Anormalidade de Onda ST-T): O coração já mostra sinais de sofrimento mesmo sem fazer esforço. É um sinal de alerta precoce.

    * Value 2 (Hipertrofia Ventricular Esquerda): Indica que o músculo do coração está "inchado" (grosso), geralmente por ter que fazer muita força para bombear o sangue contra uma pressão alta crônica.



# Modelagem com Regressão Logística

```{r}
source(here::here("R", "modelPrep.R"))
```

## Modelo com todas as variáveis

```{r}
formula1 <- condition ~ age + sex + cp + thalach + exang +
                         oldpeak + slope + ca + thal +
                         trestbps + chol + fbs + restecg

modelo1_ <- glm(formula1, data = treino, family = "binomial")

```




```{r summary-modelo-completo}
summary(modelo1_)
```

O AIC foi de 183.26. 

Embora o modelo explique bem a variável alvo, é possível observar que a maioria das covariáveis não é estatísticamente significativa, segundo o teste de Wald.

Para verificar isso, faremos um **Teste de Razão de Verossimilhanças**, verificando o impacto da retirada de cada variável.

```{r}
pander(Anova(modelo1_, type = "III", test = "LR"))

```

Aqui é possível obervar que as variáveis que mais contribuem para o modelo são: sex, cp, oldpeak, slope, ca e thal

Para verificar o impacto no modelo ao retirar essas variáveis, faremos o **Teste de Razão de Verossimilhanças** entre o modelo com todas as variáveis e o modelo sem as variáveis (age, thalach, exang, trestbps, chol, fbs, restecg)


```{r}
# Modelo reduzido ( com 6 variáveis )
modelo_reduzido_ <- glm(condition ~  sex + cp +
                        oldpeak + slope + ca + thal,
                    data = treino, 
                    family = "binomial")

pander(anova(modelo1_, modelo_reduzido_, test = "Chisq"))
```


O P-valor foi de 0.7863, ou seja, não há evidências de que o modelo com todas as variáveis seja melhor que o modelo reduzido. Então optamos pelo uso do modelo reduzido.

```{r}
pander(Anova(modelo_reduzido_, type = "III", test = "LR"))

```

Todas variáveis contribuem significativamente para o modelo.

## Analisando os coeficientes do modelo reduzido

```{r}
summary(modelo_reduzido_)
```

O AIC do modelo reduzido (171.99) foi menor que o do modelo completo, e a Deviance Residual foi aproximadamente igual. Ou seja, o modelo com menos variáveis conseguiu explicar tão bem os dados quanto o completo.

```{r}
# Calcula os Odds Ratios e os Intervalos de Confiança
intervalos <- exp(confint(modelo_reduzido_))
ors <- exp(coef(modelo_reduzido_))

# Cria o data frame e calcula a Amplitude
tabela_coef <- data.frame(
  OR = ors,
  "2.5" = intervalos[,1],
  "97.5" = intervalos[,2],
  Amplitude = intervalos[,2] - intervalos[,1] # Diferença absoluta
)

pander(tabela_coef, 
       caption = "Odds Ratios, Intervalos de Confiança e Amplitude",
       digits = 4)
```

É possível observar que alguns coeficientes estimados são muito incertos (o modelo não conseguiu definir se a associação entre a respectiva variável e o target era positiva ou negativa);

Essas variáveis foram : cp2, slope2 e thal1

Outros coeficientes tinham IC com amplitude grande demais, como foi o caso de cp3, ca3, ca2 

Ou seja, o modelo não conseguiu estimar precisamente esses coeficientes 

Uma possível motivação para isso é que essas variáveis categóricas possuem algumas classes subrepresentadas no dataset, dificultando a estimação dos parâmetros.


## Treinando modelo com agrupamento de classes subrepresentadas

* cp : 
    * com_dor : {0, 1, 2}
    * sem_dor : {3}
* slope : 
    * asc : {0}
    * not_asc : {1, 2}
* ca : 
    * zero : {0}
    * not_zero : {1, 2, 3}
* thal : 
    * normal : {0}
    * not_normal : {1, 2}

```{r}
modelo_agrupado <- glm(condition ~ sex+ cp +
                   oldpeak + slope + ca + thal, 
                 data = treino_agrupado, 
                 family = "binomial")
```




```{r}
summary(modelo_agrupado)
```

```{r}
# Calcula os Odds Ratios e os Intervalos de Confiança
intervalos <- exp(confint(modelo_agrupado))
ors <- exp(coef(modelo_agrupado))

# Cria o data frame e calcula a Amplitude
tabela_coef <- data.frame(
  OR = ors,
  "2.5" = intervalos[,1],
  "97.5" = intervalos[,2],
  Amplitude = intervalos[,2] - intervalos[,1] # Diferença absoluta
)

pander(tabela_coef, 
       caption = "Odds Ratios, Intervalos de Confiança e Amplitude",
       digits = 4)
```


Aqui, é possível observar que os parâmetros estão mais estáveis e os odds ratios estão mais de acordo com os insights obtidos na EDA;


# Criando árvore de decisão de acordo com as variáveis usadas no modelo logístico reduzido


```{r}
# Árvore de Decisão nos Dados Originais
arvore_original <- rpart(condition ~ sex + cp + oldpeak + slope + ca + thal, 
                         data = treino, 
                         method = "class")

# Árvore de Decisão nos Dados com classes agrupadas 
arvore_limpa <- rpart(condition ~ sex + cp + oldpeak + slope + ca + thal, 
                      data = treino_limpo, 
                      method = "class")

# Plotando das árvores
par(mfrow = c(1, 2))

rpart.plot(arvore_original, main = "Árvore: Dados Originais", 
           type = 4, extra = 104, under = TRUE, faclen = 0)

rpart.plot(arvore_limpa, main = "Árvore: Dados com classes agrupadas", 
           type = 4, extra = 104, under = TRUE, faclen = 0)
```

As duas árvores geradas são iguais, isso mostra que o agrupamento das classes subrepresentadas faz sentido;






## Verificando o desempenho do modelo no conjunto de teste (via boostrap)
```{r}
# BOOTSTRAP
set.seed(123)
n_boot <- 1000

# Bootstrap para os 3 modelos principais
boot_reduzido <- boot(data = teste, statistic = calc_boot_metrics, 
                      R = n_boot, modelo = modelo_reduzido_, tipo_modelo = "glm")

boot_agrupado <- boot(data = teste_agrupado, statistic = calc_boot_metrics, 
                      R = n_boot, modelo = modelo_agrupado, tipo_modelo = "glm")

boot_arvore   <- boot(data = teste_agrupado, statistic = calc_boot_metrics, 
                      R = n_boot, modelo = arvore_limpa, tipo_modelo = "tree")


tabela_bootstrap <- rbind(
  summarize_boot(boot_reduzido, "Logística Reduzida"),
  summarize_boot(boot_agrupado, "Logística Agrupada"),
  summarize_boot(boot_arvore, "Árvore de Decisão")
)


tabela_ordenada <- tabela_bootstrap %>%
  arrange(Metrica, desc(Modelo))

pander(tabela_ordenada, 
       caption = "Métricas de Performance Ordenadas (Média e IC de 95%)",
       split.table = Inf, # Evita que a tabela quebre em colunas
       digits = 4)


```


```{r}
ggplot(tabela_ordenada, aes(x = Modelo, y = Media, color = Modelo)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = IC_Lower, ymax = IC_Upper), width = 0.2, linewidth = 1) +
  facet_wrap(~Metrica, scales = "free_y") +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(
    title = "Comparação de Modelos via Bootstrap (n=59 no teste)",
    subtitle = "Pontos representam a média e barras representam o IC de 95%",
    y = "Valor da Métrica",
    x = ""
  ) +
  theme(
    axis.text.x = element_blank(), # Remove o texto do eixo X para não sobrepor
    strip.text = element_text(face = "bold", size = 10), # Estiliza o título dos quadros
    legend.position = "bottom"
  )
```

Esse gráfico mostra que o desempenho dos modelos parece ser equivalente entre os modelos, entretando, no PR-AUC, é possível observar que a árvore de decisão teve um valor muito inferior aos outros, ou seja, ela é um modelo muito sensível a pequenas mudanças.


### Teste de hipótese de diferença de médias entre o modelo logístico nos dados agrupados e a árvore de decisão

```{r}
metricas_nomes <- c("Acurácia", "Precisão", "Recall", "AUC", "PR-AUC")
resultados_testes <- data.frame()

# --- 2. LOOP PARA CÁLCULO DE P-VALOR POR MÉTRICA ---
for (i in 1:5) {
  dist_agrupada <- boot_agrupado$t[, i]
  dist_arvore   <- boot_arvore$t[, i]
  
  # Diferença das distribuições (Agrupada - Árvore)
  diff_dist <- dist_agrupada - dist_arvore
  
  # P-valor: proporção de vezes que a árvore empatou ou venceu
  p_val <- mean(diff_dist <= 0)
  
  # Armazenando resultados
  resultados_testes <- rbind(resultados_testes, data.frame(
    Métrica = metricas_nomes[i],
    Diferença_Média = mean(diff_dist),
    P_Valor = p_val,
    Significativo_05 = ifelse(p_val < 0.05, "Sim", "Não")
  ))
}

# --- 3. EXIBIÇÃO DA TABELA ---
pander(resultados_testes, 
       caption = "Teste de Hipótese via Bootstrap: Logística Agrupada vs. Árvore de Decisão",
       digits = 4)
```

### Teste de hipótese de diferença de médias entre o modelo logístico nos dados agrupados e nos dados originais
```{r}
metricas_nomes <- c("Acurácia", "Precisão", "Recall", "AUC", "PR-AUC")
resultados_testes <- data.frame()

# --- 2. LOOP PARA CÁLCULO DE P-VALOR POR MÉTRICA ---
for (i in 1:5) {
  dist_agrupada <- boot_agrupado$t[, i]
  dist_reduzido   <- boot_reduzido$t[, i]
  
  # Diferença das distribuições (Agrupada - Árvore)
  diff_dist <- dist_agrupada - dist_reduzido
  
  # P-valor: proporção de vezes que a árvore empatou ou venceu
  p_val <- mean(diff_dist <= 0)
  
  # Armazenando resultados
  resultados_testes <- rbind(resultados_testes, data.frame(
    Métrica = metricas_nomes[i],
    Diferença_Média = mean(diff_dist),
    P_Valor = p_val,
    Significativo_05 = ifelse(p_val < 0.05, "Sim", "Não")
  ))
}

# --- 3. EXIBIÇÃO DA TABELA ---
pander(resultados_testes, 
       caption = "Teste de Hipótese via Bootstrap: Logística Agrupada vs. Árvore de Decisão",
       digits = 4)
```


# Conclusão


Como não há diferenças significativas entre o desempenho do modelo logístico com e sem os dados agrupados e o modelo com classes agrupadas teve parâmetros mais "comportados", o escolheremos como o melhor modelo, nessa análise.