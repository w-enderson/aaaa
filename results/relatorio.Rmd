---
title: "Análise Estatística de Fatores de Risco para Doença Coronária"
author: "Wenderson Santos"
output: 
    html_document:
        theme: flatly
        toc: true
        code_folding: show
---


```{r setup, include=FALSE}
source(here::here("R", "imports.R"))
source(here::here("R", "getData.R"))
source(here::here("R", "getDataBin.R"))
source(here::here("R", "modelPrep.R"))

```


# Introdução
O dataset provém de um estudo que analisou 297 pacientes na Cleveland Clinic para avaliação da Doença Coronária;

O experimento envolveu 3 estágios:
 
* Teste de esforço (protocolo de Bruce) 
* Cinefluoroscopia
* Angiografia coronária
* Cintilografia com Tálio-201

## Variáveis analisadas

* age
* sex
* cp : tipo de dor no peito
    * Angina Típica: Atende a três critérios (localização atrás do osso do peito, provocada por esforço/estresse e aliviada por repouso).

    * Angina Atípica: Atende a apenas dois desses critérios.

    * Dor Não Anginosa: Atende a apenas um ou nenhum dos critérios, sugerindo que a causa pode ser muscular ou gástrica (não cardíaca).

    * Assintomático: O paciente não sente dor, mas o médico ainda assim solicitou os exames devido a outros fatores de risco (como idade ou histórico familiar).

* thalach : Frequência cardíaca máxima atingida antes da exaustão ou sintomas (no teste de esforço).
* exang : Indica se o paciente sentiu angina (dor) durante o exercício.
* oldpeak : diferença entre a posição do segmento ST (ECG) no repouso e no pico do esforço (thalac) (quanto maior essa diferença, maior é a área do coração que sofre por falta de sangue)
* slope : Enquanto o oldpeak diz o quanto a linha afundou, o slope diz como ela se comporta logo após o afundamento. Existem três tipos principais de inclinação:

    * Value 0: Upsloping (Ascendente): A linha afunda, mas sobe rápido. É comum em exercícios intensos e nem sempre indica doença grave.

    * Value 1: Flat (Plano): A linha afunda e fica "reta". É um sinal clássico e preocupante de isquemia.

    * Value 2: Downsloping (Descendente): A linha afunda e continua descendo. É o sinal mais grave de todos, indicando que o coração está em alto sofrimento isquêmico. (mesmo após a interrupção do esforço)


* ca : Número de vasos principais com depósitos de cálcio ou interrupções no fluxo.
    * 0: Nenhuma calcificação significativa (indício de artérias limpas)

    * 1, 2 o
    u 3: Indica que a doença está presente em um, dois ou três vasos principais.
* thal : Avalia se o sangue está chegando a todas as partes do coração durante o repouso e após o esforço.

    * 0 = Normal: O contraste se distribui uniformemente por todo o coração.

    * 1 = Fixed Defect (Defeito Fixo): Uma parte do coração não recebe o contraste nem no esforço, nem no repouso. Isso geralmente indica tecido morto (cicatriz de um infarto antigo).

    * 2 = Reversable Defect (Defeito Reversível): O coração parece normal em repouso, mas "falta sangue" em alguma região durante o esforço. Isso é o sinal clássico de isquemia ativa: a artéria está entupida, mas o tecido ainda está vivo e sofrendo.
* condition (target)

* trestbps : É a pressão arterial medida no momento da internação.
* fbs : Glicemia de Jejum é maior ou menor que 120mg/dl (binário)
* chol : nível total de colesterol no sangue.
* restecg : 

    * Value 0 (Normal): O coração em repouso não apresenta irregularidades elétricas.

    * Value 1 (Anormalidade de Onda ST-T): O coração já mostra sinais de sofrimento mesmo sem fazer esforço. É um sinal de alerta precoce.

    * Value 2 (Hipertrofia Ventricular Esquerda): Indica que o músculo do coração está "inchado" (grosso), geralmente por ter que fazer muita força para bombear o sangue contra uma pressão alta crônica.



# Modelagem com Regressão Logística

```{r}
source(here::here("R", "modelPrep.R"))
```

## Modelo com todas as variáveis

```{r}
formula1 <- condition ~ age + sex + cp + thalach + exang +
                         oldpeak + slope + ca + thal +
                         trestbps + chol + fbs + restecg

modelo1_ <- glm(formula1, data = treino, family = "binomial")

```




```{r summary-modelo-completo}
summary(modelo1_)
```

É possível observar que o modelo com as variáveis possui uma deviance muito menor, em relação ao modelo sem variáveis; ou seja, ele é significativo.

O AIC foi de 183.26. 

Embora o modelo explique bem a variável alvo, é possível observar que a maioria das covariáveis não é estatísticamente significativa, segundo o teste de Wald.

Para verificar isso, faremos um **Teste de Razão de Verossimilhanças**, verificando o impacto da retirada de cada variável.

```{r}
pander(Anova(modelo1_, type = "III", test = "LR"))

```

Aqui é possível obervar que as variáveis que mais contribuem para o modelo são: sex, cp, oldpeak, slope, ca e thal

Para verificar o impacto no modelo ao retirar essas variáveis, faremos o **Teste de Razão de Verossimilhanças** entre o modelo com todas as variáveis e o modelo sem as variáveis (age, thalach, exang, trestbps, chol, fbs, restecg)


```{r}
# Modelo reduzido ( com 6 variáveis )
modelo_reduzido_ <- glm(condition ~  sex + cp +
                        oldpeak + slope + ca + thal,
                    data = treino, 
                    family = "binomial")

pander(anova(modelo1_, modelo_reduzido_, test = "Chisq"))
```


O P-valor foi de 0.7863, ou seja, não há evidências de que o modelo com todas as variáveis seja melhor que o modelo reduzido. Então optamos pelo uso do modelo reduzido.

```{r}
pander(Anova(modelo_reduzido_, type = "III", test = "LR"))

```

Todas variáveis contribuem significativamente para o modelo.

## Analisando os coeficientes do modelo reduzido

```{r}
summary(modelo_reduzido_)
```

O AIC do modelo reduzido (171.99) foi menor que o do modelo com todas as variáveis, e a Deviance Residual foi aproximadamente igual. Ou seja, o modelo com menos variáveis conseguiu explicar tão bem os dados quanto o completo.

```{r}
# Calcula os Odds Ratios e os Intervalos de Confiança
intervalos <- exp(confint(modelo_reduzido_))
ors <- exp(coef(modelo_reduzido_))

# Cria o data frame e calcula a Amplitude
tabela_coef <- data.frame(
  OR = ors,
  "2.5" = intervalos[,1],
  "97.5" = intervalos[,2],
  Amplitude = intervalos[,2] - intervalos[,1] # Diferença absoluta
)

pander(tabela_coef, 
       caption = "Odds Ratios, Intervalos de Confiança e Amplitude",
       digits = 4)
```

É possível observar que alguns coeficientes estimados são muito incertos (o modelo não conseguiu definir se a associação entre a respectiva variável e o target era positiva ou negativa);

Essas variáveis foram : cp2, slope2 e thal1

Outros coeficientes tinham IC com amplitude grande demais, como foi o caso de cp3, ca3, ca2 

Ou seja, o modelo não conseguiu estimar precisamente os coeficientes 

Uma possível motivação para isso é que essas variáveis categóricas possuem algumas classes subrepresentadas no dataset, dificultando a estimação dos parâmetros.


## Treinando modelo com agrupamento de classes subrepresentadas

* cp : 
    * com_dor : {0, 1, 2}
    * sem_dor : {3}
* slope : 
    * asc : {0}
    * not_asc : {1, 2}
* ca : 
    * zero : {0}
    * not_zero : {1, 2, 3}
* thal : 
    * normal : {0}
    * not_normal : {1, 2}

```{r}
modelo_limpo <- glm(condition ~ sex+ cp +
                   oldpeak + slope + ca + thal, 
                 data = treino_limpo, 
                 family = "binomial")
```




```{r}
summary(modelo_limpo)
```

```{r}
# Calcula os Odds Ratios e os Intervalos de Confiança
intervalos <- exp(confint(modelo_limpo))
ors <- exp(coef(modelo_limpo))

# Cria o data frame e calcula a Amplitude
tabela_coef <- data.frame(
  OR = ors,
  "2.5" = intervalos[,1],
  "97.5" = intervalos[,2],
  Amplitude = intervalos[,2] - intervalos[,1] # Diferença absoluta
)

pander(tabela_coef, 
       caption = "Odds Ratios, Intervalos de Confiança e Amplitude",
       digits = 4)
```


Aqui, é possível observar que os parâmetros estão mais estáveis e os odds ratios estão mais de acordo com os resultados obtidos na EDA;


# Verificando o desempenho dos modelos no conjunto de teste

```{r}
set.seed(28)
modelo1 <- train( condition ~ sex+ cp +
                    oldpeak + slope + ca + thal,
                  data = treino,
                  method = "glm",
                  family = "binomial",
                  trControl = ctrl)

modelo2 <- train( condition ~ sex+ cp +
                    oldpeak + slope + ca + thal,
                  data = treino_limpo,
                  method = "glm",
                  family = "binomial",
                  trControl = ctrl)

resultados <- resamples(list(original = modelo1, limpo = modelo2))
```



```{r}
dotplot(resultados)
```


```{r}
# Matriz para o modelo original
p1 <- predict(modelo1, treino)
m_original <- confusionMatrix(p1, treino$condition)

# Matriz para o modelo limpo
p2 <- predict(modelo2, treino_limpo)
m_limpo <- confusionMatrix(p2, treino_limpo$condition)

# Exibindo lado a lado com pander
pander(m_original$table, caption = "Matriz de Confusão: Modelo Original")
pander(m_limpo$table, caption = "Matriz de Confusão: Modelo Limpo")
```




```{r}
# 1. Treinando a Árvore de Decisão com Dados Originais
arvore_original <- rpart(condition ~ sex + cp + oldpeak + slope + ca + thal, 
                         data = treino, 
                         method = "class")

# 2. Treinando a Árvore de Decisão com Dados Limpos
arvore_limpa <- rpart(condition ~ sex + cp + oldpeak + slope + ca + thal, 
                      data = treino_limpo, 
                      method = "class")

# 3. Plotando as árvores lado a lado para comparação
par(mfrow = c(1, 2)) # Divide a tela em 2 colunas

rpart.plot(arvore_original, main = "Árvore: Dados Originais", 
           type = 4, extra = 104, under = TRUE, faclen = 0)

rpart.plot(arvore_limpa, main = "Árvore: Dados Limpos", 
           type = 4, extra = 104, under = TRUE, faclen = 0)
```




```{r}
# --- 1. PREDIÇÕES (REGRESSÃO LOGÍSTICA) ---
# Modelo 1 (Original) no Teste Original
pred_log_orig <- predict(modelo1, teste)
cm_log_orig <- confusionMatrix(pred_log_orig, teste$condition)

# Modelo 2 (Limpo) no Teste Limpo
pred_log_limpo <- predict(modelo2, teste_limpo)
cm_log_limpo <- confusionMatrix(pred_log_limpo, teste_limpo$condition)

# --- 2. PREDIÇÕES (ÁRVORE DE DECISÃO) ---
# Árvore Original no Teste Original
pred_tree_orig <- predict(arvore_original, teste, type = "class")
cm_tree_orig <- confusionMatrix(pred_tree_orig, teste$condition)

# Árvore Limpa no Teste Limpo
pred_tree_limpa <- predict(arvore_limpa, teste_limpo, type = "class")
cm_tree_limpa <- confusionMatrix(pred_tree_limpa, teste_limpo$condition)

# --- 3. TABELA COMPARATIVA DE ACURÁCIA ---
comparativo_teste <- data.frame(
  Modelo = c("Logística Original", "Logística Limpa", "Árvore Original", "Árvore Limpa"),
  Acuracia = c(cm_log_orig$overall['Accuracy'], cm_log_limpo$overall['Accuracy'], 
               cm_tree_orig$overall['Accuracy'], cm_tree_limpa$overall['Accuracy']),
  Sensibilidade = c(cm_log_orig$byClass['Sensitivity'], cm_log_limpo$byClass['Sensitivity'], 
                    cm_tree_orig$byClass['Sensitivity'], cm_tree_limpa$byClass['Sensitivity']),
  Especificidade = c(cm_log_orig$byClass['Specificity'], cm_log_limpo$byClass['Specificity'], 
                     cm_tree_orig$byClass['Specificity'], cm_tree_limpa$byClass['Specificity'])
)

pander(comparativo_teste, caption = "Performance no Conjunto de Teste")



# --- 1. PREDIÇÕES DE PROBABILIDADE (Necessárias para AUC) ---
prob_log_orig  <- predict(modelo1, teste, type = "prob")[,2]
prob_log_limpo <- predict(modelo2, teste_limpo, type = "prob")[,2]
prob_tree_orig <- predict(arvore_original, teste, type = "prob")[,2]
prob_tree_limpa <- predict(arvore_limpa, teste_limpo, type = "prob")[,2]

# --- 2. FUNÇÃO AUXILIAR PARA MÉTRICAS ---
get_metrics <- function(pred_class, true_class, probs) {
  cm <- confusionMatrix(pred_class, true_class)
  roc_obj <- roc(true_class, probs, quiet = TRUE)
  
  return(c(
    Acc = cm$overall['Accuracy'],
    Sens = cm$byClass['Sensitivity'],
    Spec = cm$byClass['Specificity'],
    AUC = pROC::auc(roc_obj),
    PR_AUC = PRAUC(probs, ifelse(true_class == levels(true_class)[2], 1, 0))
  ))
}

# --- 3. CÁLCULO DAS MÉTRICAS ---
m1 <- get_metrics(pred_log_orig, teste$condition, prob_log_orig)
m2 <- get_metrics(pred_log_limpo, teste_limpo$condition, prob_log_limpo)
m3 <- get_metrics(pred_tree_orig, teste$condition, prob_tree_orig)
m4 <- get_metrics(pred_tree_limpa, teste_limpo$condition, prob_tree_limpa)

# --- 4. TABELA FINAL ---
comparativo_completo <- data.frame(
  Modelo = c("Logística Original", "Logística Limpa", "Árvore Original", "Árvore Limpa"),
  rbind(m1, m2, m3, m4)
)
pander(comparativo_completo, caption = "Comparativo de Performance no Teste (AUC e PR-AUC)")

# --- 5. PRINT DAS MATRIZES DE CONFUSÃO ---
cat("\n### MATRIZES DE CONFUSÃO ###\n")
pander(cm_log_orig$table, caption = "Logística Original")
pander(cm_log_limpo$table, caption = "Logística Limpa")
pander(cm_tree_orig$table, caption = "Árvore Original")
pander(cm_tree_limpa$table, caption = "Árvore Limpa")

```


